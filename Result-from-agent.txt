INFO:     Waiting for application startup.
INFO:src.api.app:Initializing DataScienceCopilot...
ü§ñ Initialized with Mistral provider - Model: mistral-large-latest
‚úÖ Cache database initialized at /home/user/app/cache_db/cache.db
‚úÖ Sessions database initialized at ./cache_db/sessions.db
‚úÖ Created new session: 9e7bbe07-2017-407d-88ed-50f24facbfac
INFO:src.api.app:‚úÖ Agent initialized with provider: mistral
INFO:src.api.app:üîß Compact prompts enabled for small context window
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:7860 (Press CTRL+C to quit)
INFO:src.api.app:Saving uploaded file to: /tmp/data_science_agent/usgs_earthquake_data_2000_2025.csv
INFO:src.api.app:File saved successfully: usgs_earthquake_data_2000_2025.csv (31852550 bytes)
INFO:src.api.app:Starting analysis with task: Train a model to predict the magnitude of the earthquake
üîç Extracting dataset schema locally (no LLM)...
‚úÖ Schema extracted: 175947 rows √ó 22 cols
   File size: 30.38 MB
üîß Using compact prompt for small context window
üíæ Saved to session: dataset=/tmp/data_science_agent/usgs_earthquake_data_2000_2025.csv, target=None
üîÑ Token budget reset (was 0/500000)
üí∞ Token budget: 0/500000 (0%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 9982 this call | 9982/500000 this minute

üîß Executing: profile_dataset
   Arguments: {
  "file_path": "/tmp/data_science_agent/usgs_earthquake_data_2000_2025.csv"
}
   ‚úì Completed: profile_dataset
üí∞ Token budget: 9982/500000 (2%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10121 this call | 20103/500000 this minute

üîß Executing: detect_data_quality_issues
   Arguments: {
  "file_path": "/tmp/data_science_agent/usgs_earthquake_data_2000_2025.csv"
}
   ‚úì Completed: detect_data_quality_issues
üí∞ Token budget: 20103/500000 (4%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10255 this call | 30358/500000 this minute

üîß Executing: clean_missing_values
   Arguments: {
  "file_path": "/tmp/data_science_agent/usgs_earthquake_data_2000_2025.csv",
  "strategy": "auto",
  "output_path": "./outputs/data/cleaned_earthquake_data.csv"
}
üóëÔ∏è  Dropped 3 columns with >40.0% missing:
    - dmin (51.03% missing)
    - horizontalError (55.21% missing)
    - magError (52.01% missing)
üîß Auto-detected strategies for 5 remaining columns with missing values
   ‚úì Completed: clean_missing_values
üí∞ Token budget: 30358/500000 (6%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10367 this call | 40725/500000 this minute

üîß Executing: encode_categorical
   Arguments: {
  "file_path": "./outputs/data/cleaned_earthquake_data.csv",
  "output_path": "./outputs/data/encoded_earthquake_data.csv",
  "method": "auto"
}
   ‚úì Completed: encode_categorical
üí∞ Token budget: 40725/500000 (8%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10470 this call | 51195/500000 this minute

üîß Executing: train_baseline_models
   Arguments: {
  "file_path": "./outputs/data/encoded_earthquake_data.csv",
  "target_col": "mag",
  "task_type": "regression"
}
üìÅ Using local filesystem backend

üé® Generating visualizations for random_forest...
   ‚úì Saved figure to ./outputs/plots/model_performance/residuals_random_forest.png
   ‚úì Residual plot
   ‚úì Saved figure to ./outputs/plots/model_performance/residuals_dist_random_forest.png
   ‚úì Residuals distribution
   ‚úì Saved figure to ./outputs/plots/model_performance/feature_importance_random_forest.png
   ‚úì Feature importance plot
   ‚úì Generated 2 performance plots
   ‚úì Completed: train_baseline_models
[DEBUG] train_baseline_models executed!
[DEBUG]   tool_result keys: ['success', 'tool', 'arguments', 'result']
[DEBUG]   'best_model' in tool_result: False
[DEBUG]   Nested result keys: ['task_type', 'n_features', 'n_samples', 'train_size', 'test_size', 'feature_names', 'models', 'best_model', 'performance_plots', 'feature_importance_plot', 'visualization_generated']
[DEBUG]   'best_model' in nested result: True
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üîÑ Token budget reset (was 51195/500000)
üí∞ Token budget: 0/500000 (0%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10543 this call | 10543/500000 this minute

üîß Executing: **Critical Error**: No models were trained. This indicates that the dataset may still contain non-numeric columns or requires further preprocessing. I will now force numeric conversion for all critical columns and retry training.  ---  **Columns to Convert**: `latitude`, `longitude`, `depth`, `mag`, `nst`, `gap` **"_errors": "coerce"** to handle non-numeric values.
   Arguments: {
  "tool": "force_numeric_conversion",
  "arguments": {
    "file_path": "./outputs/data/encoded_earthquake_data.csv",
    "columns": [
      "latitude",
      "longitude",
      "depth",
      "mag",
      "nst",
      "gap"
    ],
    "output_path": "./outputs/data/numeric_earthquake_data.csv",
    "errors": "coerce"
  }
}
   ‚úì Completed: **Critical Error**: No models were trained. This indicates that the dataset may still contain non-numeric columns or requires further preprocessing. I will now force numeric conversion for all critical columns and retry training.  ---  **Columns to Convert**: `latitude`, `longitude`, `depth`, `mag`, `nst`, `gap` **"_errors": "coerce"** to handle non-numeric values.
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üí∞ Token budget: 10543/500000 (2%)
‚è≥ Rate limiting: waiting 0.1s...
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10584 this call | 21127/500000 this minute

üîß Executing: train_baseline_models
   Arguments: {
  "file_path": "./outputs/data/numeric_earthquake_data.csv",
  "target_col": "mag",
  "task_type": "regression"
}
   ‚ùå FAILED: train_baseline_models
   ‚ö†Ô∏è  Error Type: ValidationError
   ‚ö†Ô∏è  Error Message: File not found: ./outputs/data/numeric_earthquake_data.csv
   üîÑ Recovery: Use ./outputs/data/encoded_earthquake_data.csv for next step

üî¥ CRITICAL ERROR in train_baseline_models:
   File not found: ./outputs/data/numeric_earthquake_data.csv

[DEBUG] train_baseline_models executed!
[DEBUG]   tool_result keys: ['success', 'tool', 'arguments', 'error', 'error_type', 'recovery_guidance']
[DEBUG]   'best_model' in tool_result: False
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üí∞ Token budget: 21127/500000 (4%)
‚è≥ Rate limiting: waiting 0.1s...
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10658 this call | 31785/500000 this minute

üîß Executing: force_numeric_conversion
   Arguments: {
  "file_path": "./outputs/data/encoded_earthquake_data.csv",
  "columns": [
    "latitude",
    "longitude",
    "depth",
    "mag",
    "nst",
    "gap",
    "dmin",
    "rms",
    "horizontalError",
    "depthError",
    "magError",
    "magNst"
  ],
  "output_path": "./outputs/data/numeric_earthquake_data.csv",
  "errors": "coerce"
}
üî¢ Force converting 12 columns to numeric...
‚úÖ 'latitude': Converted to numeric (no data loss)
‚úÖ 'longitude': Converted to numeric (no data loss)
‚úÖ 'depth': Converted to numeric (no data loss)
‚úÖ 'mag': Converted to numeric (no data loss)
‚úÖ 'nst': Converted to numeric (no data loss)
‚úÖ 'gap': Converted to numeric (no data loss)
‚ö†Ô∏è Column 'dmin' not found, skipping
‚úÖ 'rms': Converted to numeric (no data loss)
‚ö†Ô∏è Column 'horizontalError' not found, skipping
‚úÖ 'depthError': Converted to numeric (no data loss)
‚ö†Ô∏è Column 'magError' not found, skipping
‚úÖ 'magNst': Converted to numeric (no data loss)
   ‚úì Completed: force_numeric_conversion
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üí∞ Token budget: 31785/500000 (6%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10650 this call | 42435/500000 this minute

üîß Executing: train_baseline_models
   Arguments: {
  "file_path": "./outputs/data/numeric_earthquake_data.csv",
  "target_col": "mag",
  "task_type": "regression"
}

üé® Generating visualizations for random_forest...
   ‚úì Saved figure to ./outputs/plots/model_performance/residuals_random_forest.png
   ‚úì Residual plot
   ‚úì Saved figure to ./outputs/plots/model_performance/residuals_dist_random_forest.png
   ‚úì Residuals distribution
   ‚úì Saved figure to ./outputs/plots/model_performance/feature_importance_random_forest.png
   ‚úì Feature importance plot
   ‚úì Generated 2 performance plots
   ‚úì Completed: train_baseline_models
[DEBUG] train_baseline_models executed!
[DEBUG]   tool_result keys: ['success', 'tool', 'arguments', 'result']
[DEBUG]   'best_model' in tool_result: False
[DEBUG]   Nested result keys: ['task_type', 'n_features', 'n_samples', 'train_size', 'test_size', 'feature_names', 'models', 'best_model', 'performance_plots', 'feature_importance_plot', 'visualization_generated']
[DEBUG]   'best_model' in nested result: True
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üîÑ Token budget reset (was 42435/500000)
üí∞ Token budget: 0/500000 (0%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10676 this call | 10676/500000 this minute

üîß Executing: hyperparameter_tuning
   Arguments: {
  "file_path": "./outputs/data/numeric_earthquake_data.csv",
  "target_col": "mag",
  "model_type": "xgboost",
  "task_type": "regression",
  "output_path": "./outputs/models/hyperparameter_tuned_model.pkl"
}
   üîÑ Converting Polars DataFrame to Pandas for XGBoost compatibility...
   ‚ö†Ô∏è Dropping 2 datetime columns that cannot be used directly: ['time', 'updated']
   üí° Time features should have been extracted in workflow step 7 (create_time_features)
   ‚ö†Ô∏è Dropping 8 string columns that weren't encoded: ['magType', 'net', 'id', 'place', 'type', 'status', 'locationSource', 'magSource']
   üí° Categorical encoding should have been done in workflow step 8 (encode_categorical)
   üí° These columns likely weren't in the encoded file or encoding failed
üîß Starting hyperparameter tuning with 50 trials...
[I 2025-12-30 06:45:29,933] A new study created in memory with name: no-name-f5e1b6c2-6c53-427f-914b-8eaf8b5a27d1
[I 2025-12-30 06:45:35,182] Trial 0 finished with value: -0.2222053027498337 and parameters: {'n_estimators': 218, 'max_depth': 10, 'learning_rate': 0.1205712628744377, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'gamma': 0.7799726016810132, 'reg_alpha': 0.11616722433639892, 'reg_lambda': 1.7323522915498704}. Best is trial 0 with value: -0.2222053027498337.
[I 2025-12-30 06:45:45,350] Trial 1 finished with value: -0.2249593434033464 and parameters: {'n_estimators': 321, 'max_depth': 8, 'learning_rate': 0.010725209743171997, 'subsample': 0.9849549260809971, 'colsample_bytree': 0.9162213204002109, 'gamma': 1.0616955533913808, 'reg_alpha': 0.36364993441420124, 'reg_lambda': 0.36680901970686763}. Best is trial 0 with value: -0.2222053027498337.
[I 2025-12-30 06:45:49,296] Trial 2 finished with value: -0.2227477999692053 and parameters: {'n_estimators': 187, 'max_depth': 7, 'learning_rate': 0.04345454109729477, 'subsample': 0.645614570099021, 'colsample_bytree': 0.8059264473611898, 'gamma': 0.6974693032602092, 'reg_alpha': 0.5842892970704363, 'reg_lambda': 0.7327236865873834}. Best is trial 0 with value: -0.2222053027498337.
[I 2025-12-30 06:45:58,519] Trial 3 finished with value: -0.217909780849128 and parameters: {'n_estimators': 255, 'max_depth': 9, 'learning_rate': 0.019721610970574007, 'subsample': 0.7571172192068059, 'colsample_bytree': 0.7962072844310213, 'gamma': 0.23225206359998862, 'reg_alpha': 1.2150897038028767, 'reg_lambda': 0.34104824737458306}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:45:59,937] Trial 4 finished with value: -0.22015938346470731 and parameters: {'n_estimators': 79, 'max_depth': 10, 'learning_rate': 0.26690431824362526, 'subsample': 0.9041986740582306, 'colsample_bytree': 0.6523068845866853, 'gamma': 0.48836057003191935, 'reg_alpha': 1.3684660530243138, 'reg_lambda': 0.8803049874792026}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:46:02,582] Trial 5 finished with value: -0.2748644699216113 and parameters: {'n_estimators': 105, 'max_depth': 6, 'learning_rate': 0.011240768803005551, 'subsample': 0.954660201039391, 'colsample_bytree': 0.6293899908000085, 'gamma': 3.31261142176991, 'reg_alpha': 0.6234221521788219, 'reg_lambda': 1.0401360423556216}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:46:04,593] Trial 6 finished with value: -0.2419585802420717 and parameters: {'n_estimators': 296, 'max_depth': 4, 'learning_rate': 0.27051668818999286, 'subsample': 0.8875664116805573, 'colsample_bytree': 0.9697494707820946, 'gamma': 4.474136752138244, 'reg_alpha': 1.1957999576221703, 'reg_lambda': 1.8437484700462337}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:46:06,507] Trial 7 finished with value: -0.29437110404691424 and parameters: {'n_estimators': 89, 'max_depth': 4, 'learning_rate': 0.011662890273931383, 'subsample': 0.6626651653816322, 'colsample_bytree': 0.6943386448447411, 'gamma': 1.3567451588694794, 'reg_alpha': 1.6574750183038587, 'reg_lambda': 0.7135066533871786}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:46:10,089] Trial 8 finished with value: -0.2447564815895217 and parameters: {'n_estimators': 176, 'max_depth': 7, 'learning_rate': 0.016149614799999188, 'subsample': 0.9010984903770198, 'colsample_bytree': 0.5372753218398854, 'gamma': 4.9344346830025865, 'reg_alpha': 1.5444895385933148, 'reg_lambda': 0.3974313630683448}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:46:12,248] Trial 9 finished with value: -0.21816234213013597 and parameters: {'n_estimators': 52, 'max_depth': 9, 'learning_rate': 0.11069143219393454, 'subsample': 0.8645035840204937, 'colsample_bytree': 0.8856351733429728, 'gamma': 0.3702232586704518, 'reg_alpha': 0.7169314570885452, 'reg_lambda': 0.23173811905025943}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:46:18,078] Trial 10 finished with value: -0.23147161506987665 and parameters: {'n_estimators': 465, 'max_depth': 6, 'learning_rate': 0.028477486830279865, 'subsample': 0.5089809378074098, 'colsample_bytree': 0.7828065453407016, 'gamma': 2.1340644769165706, 'reg_alpha': 1.9195414918908396, 'reg_lambda': 0.023705191223290734}. Best is trial 3 with value: -0.217909780849128.
[I 2025-12-30 06:46:23,446] Trial 11 finished with value: -0.2151015417478106 and parameters: {'n_estimators': 403, 'max_depth': 9, 'learning_rate': 0.09191338148828515, 'subsample': 0.7792623653896451, 'colsample_bytree': 0.8582355933427974, 'gamma': 0.18425648529685623, 'reg_alpha': 0.9194876161876269, 'reg_lambda': 0.031300641140509095}. Best is trial 11 with value: -0.2151015417478106.
[I 2025-12-30 06:46:36,820] Trial 12 finished with value: -0.2117902331886637 and parameters: {'n_estimators': 394, 'max_depth': 9, 'learning_rate': 0.06863000803064562, 'subsample': 0.7316936986365619, 'colsample_bytree': 0.8463063352248831, 'gamma': 0.03755154871269628, 'reg_alpha': 0.9374104377756843, 'reg_lambda': 1.305362400449962}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:46:40,470] Trial 13 finished with value: -0.2266597710002857 and parameters: {'n_estimators': 412, 'max_depth': 8, 'learning_rate': 0.0762265316764627, 'subsample': 0.6713996441331581, 'colsample_bytree': 0.8362328309841128, 'gamma': 1.9044113038612998, 'reg_alpha': 0.8762603349822686, 'reg_lambda': 1.383152643307522}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:46:44,322] Trial 14 finished with value: -0.2276988638905403 and parameters: {'n_estimators': 386, 'max_depth': 9, 'learning_rate': 0.05451959152725668, 'subsample': 0.7307024197434439, 'colsample_bytree': 0.9881376590275984, 'gamma': 2.7453009991630744, 'reg_alpha': 0.9844135581240167, 'reg_lambda': 1.3186317339532316}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:46:54,551] Trial 15 finished with value: -0.21590068160545198 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.14810350614905562, 'subsample': 0.5827781406926889, 'colsample_bytree': 0.7261631564388042, 'gamma': 0.06741926023488681, 'reg_alpha': 0.3376623139328573, 'reg_lambda': 1.3836696404640405}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:46:57,957] Trial 16 finished with value: -0.23044345798047142 and parameters: {'n_estimators': 356, 'max_depth': 5, 'learning_rate': 0.07522074480248636, 'subsample': 0.8043677189496615, 'colsample_bytree': 0.8805304594988683, 'gamma': 1.4838423870951747, 'reg_alpha': 1.0921932982341873, 'reg_lambda': 1.1332181873047948}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:02,913] Trial 17 finished with value: -0.2297064199198806 and parameters: {'n_estimators': 432, 'max_depth': 10, 'learning_rate': 0.036439114994644674, 'subsample': 0.7152394696038648, 'colsample_bytree': 0.9329945684888148, 'gamma': 3.5359723928317566, 'reg_alpha': 0.8311426266898979, 'reg_lambda': 1.6741177035341803}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:05,918] Trial 18 finished with value: -0.23947054644773408 and parameters: {'n_estimators': 324, 'max_depth': 3, 'learning_rate': 0.17221016908349282, 'subsample': 0.8132394567758081, 'colsample_bytree': 0.8460287068036322, 'gamma': 1.601698676289583, 'reg_alpha': 1.4252872924751308, 'reg_lambda': 1.5929573778842099}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:10,192] Trial 19 finished with value: -0.22885246086233257 and parameters: {'n_estimators': 379, 'max_depth': 9, 'learning_rate': 0.07728105224926932, 'subsample': 0.5855637950430337, 'colsample_bytree': 0.7458998183808371, 'gamma': 2.5072850771118333, 'reg_alpha': 0.40508143887559434, 'reg_lambda': 0.6996128559265311}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:14,403] Trial 20 finished with value: -0.22178011083009927 and parameters: {'n_estimators': 446, 'max_depth': 8, 'learning_rate': 0.09325109683406559, 'subsample': 0.8366733523272174, 'colsample_bytree': 0.8665596769741382, 'gamma': 0.8841313654895134, 'reg_alpha': 0.07301978703020784, 'reg_lambda': 1.1644418562350771}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:31,021] Trial 21 finished with value: -0.21750518779758 and parameters: {'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.16161445557774798, 'subsample': 0.5637259373457058, 'colsample_bytree': 0.7431023122103961, 'gamma': 0.008554418542379934, 'reg_alpha': 0.41589858991129514, 'reg_lambda': 1.44382210900569}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:42,866] Trial 22 finished with value: -0.21604211701365877 and parameters: {'n_estimators': 485, 'max_depth': 7, 'learning_rate': 0.1517966056201532, 'subsample': 0.5975118290673396, 'colsample_bytree': 0.7057679936639524, 'gamma': 0.03273020246708382, 'reg_alpha': 0.18115333465182792, 'reg_lambda': 1.9468582820569833}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:48,365] Trial 23 finished with value: -0.22410459424075588 and parameters: {'n_estimators': 415, 'max_depth': 9, 'learning_rate': 0.06106814515924398, 'subsample': 0.5064075192827886, 'colsample_bytree': 0.8192663263075712, 'gamma': 1.1768326154018607, 'reg_alpha': 0.9490825960489868, 'reg_lambda': 1.5285386073862965}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:51,863] Trial 24 finished with value: -0.22117335811388256 and parameters: {'n_estimators': 350, 'max_depth': 8, 'learning_rate': 0.20632379438852388, 'subsample': 0.7581761627346326, 'colsample_bytree': 0.7685567255706158, 'gamma': 0.559806388689428, 'reg_alpha': 0.7419450417672374, 'reg_lambda': 1.2536844729346979}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:47:57,934] Trial 25 finished with value: -0.21632616626061657 and parameters: {'n_estimators': 460, 'max_depth': 10, 'learning_rate': 0.10945058120802637, 'subsample': 0.6985777775995651, 'colsample_bytree': 0.9074136202529427, 'gamma': 0.3048175873616225, 'reg_alpha': 0.5316214539678321, 'reg_lambda': 0.004681576377994469}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:03,794] Trial 26 finished with value: -0.2209694267468243 and parameters: {'n_estimators': 396, 'max_depth': 9, 'learning_rate': 0.05177877764511362, 'subsample': 0.6239662118347137, 'colsample_bytree': 0.702747133361705, 'gamma': 0.8224402237649189, 'reg_alpha': 0.23964150264576667, 'reg_lambda': 0.9921258966529627}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:10,108] Trial 27 finished with value: -0.21391152567953936 and parameters: {'n_estimators': 271, 'max_depth': 7, 'learning_rate': 0.12776364618033317, 'subsample': 0.7567579552596243, 'colsample_bytree': 0.9556430894288981, 'gamma': 0.06948779089508372, 'reg_alpha': 1.1198282172896126, 'reg_lambda': 0.5400689085271295}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:14,486] Trial 28 finished with value: -0.22869873499157783 and parameters: {'n_estimators': 259, 'max_depth': 6, 'learning_rate': 0.030857978486734355, 'subsample': 0.7848935918616498, 'colsample_bytree': 0.9571604269437145, 'gamma': 1.7876165058603275, 'reg_alpha': 1.0952368163385366, 'reg_lambda': 0.5681630769000812}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:17,444] Trial 29 finished with value: -0.22872126942543622 and parameters: {'n_estimators': 211, 'max_depth': 5, 'learning_rate': 0.09458619429934313, 'subsample': 0.7752412300256623, 'colsample_bytree': 0.9379985581491168, 'gamma': 0.9793811650600847, 'reg_alpha': 1.350816555909763, 'reg_lambda': 0.15706451357289275}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:21,314] Trial 30 finished with value: -0.21925361161197748 and parameters: {'n_estimators': 287, 'max_depth': 10, 'learning_rate': 0.1127332265321615, 'subsample': 0.693505577796114, 'colsample_bytree': 0.9942074947806865, 'gamma': 0.6391203439145869, 'reg_alpha': 1.2176992426241886, 'reg_lambda': 0.5294343996093583}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:27,860] Trial 31 finished with value: -0.2143322551364602 and parameters: {'n_estimators': 233, 'max_depth': 7, 'learning_rate': 0.13506979382521442, 'subsample': 0.7375210914463181, 'colsample_bytree': 0.8517121503192013, 'gamma': 0.036560967437380035, 'reg_alpha': 0.7982259777780396, 'reg_lambda': 0.8709228334252379}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:31,086] Trial 32 finished with value: -0.2204394869608693 and parameters: {'n_estimators': 224, 'max_depth': 7, 'learning_rate': 0.1303776200625617, 'subsample': 0.8231985730436107, 'colsample_bytree': 0.8628533393513916, 'gamma': 0.3959034967984258, 'reg_alpha': 0.8014731789781997, 'reg_lambda': 0.80598494190566}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:33,280] Trial 33 finished with value: -0.22562646149513776 and parameters: {'n_estimators': 152, 'max_depth': 7, 'learning_rate': 0.21074358348676045, 'subsample': 0.7286349092078599, 'colsample_bytree': 0.9068137156850165, 'gamma': 1.1155945323427658, 'reg_alpha': 1.0554400512203728, 'reg_lambda': 0.9422210002428226}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:39,212] Trial 34 finished with value: -0.22049764075026887 and parameters: {'n_estimators': 327, 'max_depth': 5, 'learning_rate': 0.06604216273735086, 'subsample': 0.7391652879271879, 'colsample_bytree': 0.8278094396951904, 'gamma': 0.006092262001214863, 'reg_alpha': 0.9123457635515685, 'reg_lambda': 0.5711862639803287}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:42,620] Trial 35 finished with value: -0.22388793990803135 and parameters: {'n_estimators': 233, 'max_depth': 6, 'learning_rate': 0.08993476471600502, 'subsample': 0.7703347328258917, 'colsample_bytree': 0.9010371701372613, 'gamma': 0.6809389626726724, 'reg_alpha': 0.6727179992050063, 'reg_lambda': 0.4106268636514421}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:47,953] Trial 36 finished with value: -0.2194321126991153 and parameters: {'n_estimators': 301, 'max_depth': 7, 'learning_rate': 0.04519709940232653, 'subsample': 0.858979173354254, 'colsample_bytree': 0.8065580557240736, 'gamma': 0.34223620291079404, 'reg_alpha': 0.5518537237664257, 'reg_lambda': 0.17327977402568823}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:50,904] Trial 37 finished with value: -0.22113781824020878 and parameters: {'n_estimators': 262, 'max_depth': 8, 'learning_rate': 0.1237083896420413, 'subsample': 0.6955486189796809, 'colsample_bytree': 0.9405129028663352, 'gamma': 0.6858920712841973, 'reg_alpha': 1.2292591675578928, 'reg_lambda': 0.8322760011399029}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:52,621] Trial 38 finished with value: -0.2304114385187297 and parameters: {'n_estimators': 187, 'max_depth': 10, 'learning_rate': 0.19767773627157836, 'subsample': 0.7913259854855206, 'colsample_bytree': 0.8523458057115616, 'gamma': 3.8370761624114746, 'reg_alpha': 1.006545290140675, 'reg_lambda': 1.0925731093851638}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:54,852] Trial 39 finished with value: -0.2234989284908891 and parameters: {'n_estimators': 133, 'max_depth': 9, 'learning_rate': 0.09107282452904876, 'subsample': 0.975419047477103, 'colsample_bytree': 0.6406089351880103, 'gamma': 1.2778641187103894, 'reg_alpha': 1.2997656298230078, 'reg_lambda': 0.6705825086913518}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:48:58,702] Trial 40 finished with value: -0.21992454490010543 and parameters: {'n_estimators': 355, 'max_depth': 7, 'learning_rate': 0.2986164631468, 'subsample': 0.6394649808529335, 'colsample_bytree': 0.7762584166863378, 'gamma': 0.2456415206010749, 'reg_alpha': 1.5456886180253895, 'reg_lambda': 0.2752282375196218}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:04,353] Trial 41 finished with value: -0.21619945709301386 and parameters: {'n_estimators': 239, 'max_depth': 8, 'learning_rate': 0.14126481383258627, 'subsample': 0.5396686243791224, 'colsample_bytree': 0.7268528342226097, 'gamma': 0.11702816721319677, 'reg_alpha': 0.3191223725020149, 'reg_lambda': 1.2917550630353662}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:07,002] Trial 42 finished with value: -0.2205597452422415 and parameters: {'n_estimators': 276, 'max_depth': 8, 'learning_rate': 0.18271793396417674, 'subsample': 0.7511142037720665, 'colsample_bytree': 0.8000301847875506, 'gamma': 0.5452778280207482, 'reg_alpha': 1.1022163980543684, 'reg_lambda': 1.1950174269359606}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:10,315] Trial 43 finished with value: -0.21988315364230107 and parameters: {'n_estimators': 308, 'max_depth': 9, 'learning_rate': 0.24872849794097893, 'subsample': 0.6701120513607601, 'colsample_bytree': 0.5643131665359047, 'gamma': 0.2750257841501685, 'reg_alpha': 0.8050301950940839, 'reg_lambda': 1.4396458070433622}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:12,714] Trial 44 finished with value: -0.2220612075002763 and parameters: {'n_estimators': 201, 'max_depth': 8, 'learning_rate': 0.14186455955627142, 'subsample': 0.9252495145114167, 'colsample_bytree': 0.5007250058963767, 'gamma': 0.5007826134971919, 'reg_alpha': 0.02006171752165614, 'reg_lambda': 1.0395915501076223}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:16,214] Trial 45 finished with value: -0.2268322456721617 and parameters: {'n_estimators': 424, 'max_depth': 6, 'learning_rate': 0.10452400342643785, 'subsample': 0.8515596270392202, 'colsample_bytree': 0.6780402724214556, 'gamma': 0.9100993087116295, 'reg_alpha': 0.4665290048783967, 'reg_lambda': 1.720530145645983}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:21,114] Trial 46 finished with value: -0.21688489119504073 and parameters: {'n_estimators': 463, 'max_depth': 9, 'learning_rate': 0.1270881474380103, 'subsample': 0.7192500291857469, 'colsample_bytree': 0.6719865546958231, 'gamma': 0.23509229649869182, 'reg_alpha': 0.6068107464862611, 'reg_lambda': 0.9193788086925786}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:25,554] Trial 47 finished with value: -0.23038515359268302 and parameters: {'n_estimators': 480, 'max_depth': 8, 'learning_rate': 0.07663171461168965, 'subsample': 0.6217060709053571, 'colsample_bytree': 0.8836458414460989, 'gamma': 3.1089183574109462, 'reg_alpha': 1.1711822917047499, 'reg_lambda': 1.584883446591926}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:35,002] Trial 48 finished with value: -0.2160270955809555 and parameters: {'n_estimators': 370, 'max_depth': 7, 'learning_rate': 0.23531575366912716, 'subsample': 0.8785548777891196, 'colsample_bytree': 0.9661628595952791, 'gamma': 0.0211536688019886, 'reg_alpha': 0.7000473568815796, 'reg_lambda': 0.4607724758064207}. Best is trial 12 with value: -0.2117902331886637.
[I 2025-12-30 06:49:39,584] Trial 49 finished with value: -0.22058191837354965 and parameters: {'n_estimators': 337, 'max_depth': 9, 'learning_rate': 0.06766630550571712, 'subsample': 0.8075461050783281, 'colsample_bytree': 0.605081846741258, 'gamma': 0.4661956445976906, 'reg_alpha': 1.8556268720042601, 'reg_lambda': 1.3519760648769108}. Best is trial 12 with value: -0.2117902331886637.
  0%|          | 0/50 [00:00<?, ?it/s]
                                      

  0%|          | 0/50 [00:05<?, ?it/s]
Best trial: 0. Best value: -0.222205:   0%|          | 0/50 [00:05<?, ?it/s]
Best trial: 0. Best value: -0.222205:   2%|‚ñè         | 1/50 [00:05<04:17,  5.25s/it]
                                                                                    

Best trial: 0. Best value: -0.222205:   2%|‚ñè         | 1/50 [00:15<04:17,  5.25s/it]
Best trial: 0. Best value: -0.222205:   2%|‚ñè         | 1/50 [00:15<04:17,  5.25s/it]
Best trial: 0. Best value: -0.222205:   4%|‚ñç         | 2/50 [00:15<06:30,  8.14s/it]
                                                                                    

Best trial: 0. Best value: -0.222205:   4%|‚ñç         | 2/50 [00:19<06:30,  8.14s/it]
Best trial: 0. Best value: -0.222205:   4%|‚ñç         | 2/50 [00:19<06:30,  8.14s/it]
Best trial: 0. Best value: -0.222205:   6%|‚ñå         | 3/50 [00:19<04:52,  6.23s/it]
                                                                                    

Best trial: 0. Best value: -0.222205:   6%|‚ñå         | 3/50 [00:28<04:52,  6.23s/it]
Best trial: 3. Best value: -0.21791:   6%|‚ñå         | 3/50 [00:28<04:52,  6.23s/it] 
Best trial: 3. Best value: -0.21791:   8%|‚ñä         | 4/50 [00:28<05:40,  7.41s/it]
                                                                                   

Best trial: 3. Best value: -0.21791:   8%|‚ñä         | 4/50 [00:30<05:40,  7.41s/it]
Best trial: 3. Best value: -0.21791:   8%|‚ñä         | 4/50 [00:30<05:40,  7.41s/it]
Best trial: 3. Best value: -0.21791:  10%|‚ñà         | 5/50 [00:30<03:56,  5.25s/it]
                                                                                   

Best trial: 3. Best value: -0.21791:  10%|‚ñà         | 5/50 [00:32<03:56,  5.25s/it]
Best trial: 3. Best value: -0.21791:  10%|‚ñà         | 5/50 [00:32<03:56,  5.25s/it]
Best trial: 3. Best value: -0.21791:  12%|‚ñà‚ñè        | 6/50 [00:32<03:11,  4.36s/it]
                                                                                   

Best trial: 3. Best value: -0.21791:  12%|‚ñà‚ñè        | 6/50 [00:34<03:11,  4.36s/it]
Best trial: 3. Best value: -0.21791:  12%|‚ñà‚ñè        | 6/50 [00:34<03:11,  4.36s/it]
Best trial: 3. Best value: -0.21791:  14%|‚ñà‚ñç        | 7/50 [00:34<02:34,  3.59s/it]
                                                                                   

Best trial: 3. Best value: -0.21791:  14%|‚ñà‚ñç        | 7/50 [00:36<02:34,  3.59s/it]
Best trial: 3. Best value: -0.21791:  14%|‚ñà‚ñç        | 7/50 [00:36<02:34,  3.59s/it]
Best trial: 3. Best value: -0.21791:  16%|‚ñà‚ñå        | 8/50 [00:36<02:08,  3.06s/it]
                                                                                   

Best trial: 3. Best value: -0.21791:  16%|‚ñà‚ñå        | 8/50 [00:40<02:08,  3.06s/it]
Best trial: 3. Best value: -0.21791:  16%|‚ñà‚ñå        | 8/50 [00:40<02:08,  3.06s/it]
Best trial: 3. Best value: -0.21791:  18%|‚ñà‚ñä        | 9/50 [00:40<02:12,  3.22s/it]
                                                                                   

Best trial: 3. Best value: -0.21791:  18%|‚ñà‚ñä        | 9/50 [00:42<02:12,  3.22s/it]
Best trial: 3. Best value: -0.21791:  18%|‚ñà‚ñä        | 9/50 [00:42<02:12,  3.22s/it]
Best trial: 3. Best value: -0.21791:  20%|‚ñà‚ñà        | 10/50 [00:42<01:55,  2.89s/it]
                                                                                    

Best trial: 3. Best value: -0.21791:  20%|‚ñà‚ñà        | 10/50 [00:48<01:55,  2.89s/it]
Best trial: 3. Best value: -0.21791:  20%|‚ñà‚ñà        | 10/50 [00:48<01:55,  2.89s/it]
Best trial: 3. Best value: -0.21791:  22%|‚ñà‚ñà‚ñè       | 11/50 [00:48<02:27,  3.79s/it]
                                                                                    

Best trial: 3. Best value: -0.21791:  22%|‚ñà‚ñà‚ñè       | 11/50 [00:53<02:27,  3.79s/it]
Best trial: 11. Best value: -0.215102:  22%|‚ñà‚ñà‚ñè       | 11/50 [00:53<02:27,  3.79s/it]
Best trial: 11. Best value: -0.215102:  24%|‚ñà‚ñà‚ñç       | 12/50 [00:53<02:42,  4.27s/it]
                                                                                      

Best trial: 11. Best value: -0.215102:  24%|‚ñà‚ñà‚ñç       | 12/50 [01:06<02:42,  4.27s/it]
Best trial: 12. Best value: -0.21179:  24%|‚ñà‚ñà‚ñç       | 12/50 [01:06<02:42,  4.27s/it] 
Best trial: 12. Best value: -0.21179:  26%|‚ñà‚ñà‚ñå       | 13/50 [01:06<04:20,  7.03s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  26%|‚ñà‚ñà‚ñå       | 13/50 [01:10<04:20,  7.03s/it]
Best trial: 12. Best value: -0.21179:  26%|‚ñà‚ñà‚ñå       | 13/50 [01:10<04:20,  7.03s/it]
Best trial: 12. Best value: -0.21179:  28%|‚ñà‚ñà‚ñä       | 14/50 [01:10<03:36,  6.01s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  28%|‚ñà‚ñà‚ñä       | 14/50 [01:14<03:36,  6.01s/it]
Best trial: 12. Best value: -0.21179:  28%|‚ñà‚ñà‚ñä       | 14/50 [01:14<03:36,  6.01s/it]
Best trial: 12. Best value: -0.21179:  30%|‚ñà‚ñà‚ñà       | 15/50 [01:14<03:07,  5.36s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  30%|‚ñà‚ñà‚ñà       | 15/50 [01:24<03:07,  5.36s/it]
Best trial: 12. Best value: -0.21179:  30%|‚ñà‚ñà‚ñà       | 15/50 [01:24<03:07,  5.36s/it]
Best trial: 12. Best value: -0.21179:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [01:24<03:52,  6.82s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [01:28<03:52,  6.82s/it]
Best trial: 12. Best value: -0.21179:  32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [01:28<03:52,  6.82s/it]
Best trial: 12. Best value: -0.21179:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [01:28<03:11,  5.80s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [01:32<03:11,  5.80s/it]
Best trial: 12. Best value: -0.21179:  34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [01:32<03:11,  5.80s/it]
Best trial: 12. Best value: -0.21179:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [01:32<02:57,  5.54s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [01:35<02:57,  5.54s/it]
Best trial: 12. Best value: -0.21179:  36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [01:35<02:57,  5.54s/it]
Best trial: 12. Best value: -0.21179:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [01:35<02:28,  4.78s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [01:40<02:28,  4.78s/it]
Best trial: 12. Best value: -0.21179:  38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [01:40<02:28,  4.78s/it]
Best trial: 12. Best value: -0.21179:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:40<02:18,  4.63s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:44<02:18,  4.63s/it]
Best trial: 12. Best value: -0.21179:  40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [01:44<02:18,  4.63s/it]
Best trial: 12. Best value: -0.21179:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [01:44<02:10,  4.50s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [02:01<02:10,  4.50s/it]
Best trial: 12. Best value: -0.21179:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [02:01<02:10,  4.50s/it]
Best trial: 12. Best value: -0.21179:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [02:01<03:47,  8.14s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [02:12<03:47,  8.14s/it]
Best trial: 12. Best value: -0.21179:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [02:12<03:47,  8.14s/it]
Best trial: 12. Best value: -0.21179:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [02:12<04:09,  9.25s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [02:18<04:09,  9.25s/it]
Best trial: 12. Best value: -0.21179:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [02:18<04:09,  9.25s/it]
Best trial: 12. Best value: -0.21179:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [02:18<03:31,  8.13s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [02:21<03:31,  8.13s/it]
Best trial: 12. Best value: -0.21179:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [02:21<03:31,  8.13s/it]
Best trial: 12. Best value: -0.21179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [02:21<02:48,  6.74s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [02:27<02:48,  6.74s/it]
Best trial: 12. Best value: -0.21179:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [02:28<02:48,  6.74s/it]
Best trial: 12. Best value: -0.21179:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [02:28<02:36,  6.54s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [02:33<02:36,  6.54s/it]
Best trial: 12. Best value: -0.21179:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [02:33<02:36,  6.54s/it]
Best trial: 12. Best value: -0.21179:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [02:33<02:25,  6.33s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [02:40<02:25,  6.33s/it]
Best trial: 12. Best value: -0.21179:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [02:40<02:25,  6.33s/it]
Best trial: 12. Best value: -0.21179:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [02:40<02:19,  6.33s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [02:44<02:19,  6.33s/it]
Best trial: 12. Best value: -0.21179:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [02:44<02:19,  6.33s/it]
Best trial: 12. Best value: -0.21179:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [02:44<02:00,  5.74s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [02:47<02:00,  5.74s/it]
Best trial: 12. Best value: -0.21179:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [02:47<02:00,  5.74s/it]
Best trial: 12. Best value: -0.21179:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [02:47<01:38,  4.91s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [02:51<01:38,  4.91s/it]
Best trial: 12. Best value: -0.21179:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [02:51<01:38,  4.91s/it]
Best trial: 12. Best value: -0.21179:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [02:51<01:27,  4.60s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [02:57<01:27,  4.60s/it]
Best trial: 12. Best value: -0.21179:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [02:57<01:27,  4.60s/it]
Best trial: 12. Best value: -0.21179:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [02:57<01:33,  5.18s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [03:01<01:33,  5.18s/it]
Best trial: 12. Best value: -0.21179:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [03:01<01:33,  5.18s/it]
Best trial: 12. Best value: -0.21179:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [03:01<01:18,  4.59s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [03:03<01:18,  4.59s/it]
Best trial: 12. Best value: -0.21179:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [03:03<01:18,  4.59s/it]
Best trial: 12. Best value: -0.21179:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [03:03<01:01,  3.87s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [03:09<01:01,  3.87s/it]
Best trial: 12. Best value: -0.21179:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [03:09<01:01,  3.87s/it]
Best trial: 12. Best value: -0.21179:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [03:09<01:07,  4.49s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [03:12<01:07,  4.49s/it]
Best trial: 12. Best value: -0.21179:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [03:12<01:07,  4.49s/it]
Best trial: 12. Best value: -0.21179:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [03:12<00:58,  4.17s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [03:18<00:58,  4.17s/it]
Best trial: 12. Best value: -0.21179:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [03:18<00:58,  4.17s/it]
Best trial: 12. Best value: -0.21179:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [03:18<00:58,  4.52s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [03:20<00:58,  4.52s/it]
Best trial: 12. Best value: -0.21179:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [03:20<00:58,  4.52s/it]
Best trial: 12. Best value: -0.21179:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [03:20<00:48,  4.05s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [03:22<00:48,  4.05s/it]
Best trial: 12. Best value: -0.21179:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [03:22<00:48,  4.05s/it]
Best trial: 12. Best value: -0.21179:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [03:22<00:36,  3.35s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [03:24<00:36,  3.35s/it]
Best trial: 12. Best value: -0.21179:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [03:24<00:36,  3.35s/it]
Best trial: 12. Best value: -0.21179:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [03:24<00:30,  3.01s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [03:28<00:30,  3.01s/it]
Best trial: 12. Best value: -0.21179:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [03:28<00:30,  3.01s/it]
Best trial: 12. Best value: -0.21179:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [03:28<00:29,  3.26s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [03:34<00:29,  3.26s/it]
Best trial: 12. Best value: -0.21179:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [03:34<00:29,  3.26s/it]
Best trial: 12. Best value: -0.21179:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [03:34<00:31,  3.98s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [03:37<00:31,  3.98s/it]
Best trial: 12. Best value: -0.21179:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [03:37<00:31,  3.98s/it]
Best trial: 12. Best value: -0.21179:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [03:37<00:25,  3.58s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [03:40<00:25,  3.58s/it]
Best trial: 12. Best value: -0.21179:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [03:40<00:25,  3.58s/it]
Best trial: 12. Best value: -0.21179:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [03:40<00:21,  3.50s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [03:42<00:21,  3.50s/it]
Best trial: 12. Best value: -0.21179:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [03:42<00:21,  3.50s/it]
Best trial: 12. Best value: -0.21179:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [03:42<00:15,  3.17s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [03:46<00:15,  3.17s/it]
Best trial: 12. Best value: -0.21179:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [03:46<00:15,  3.17s/it]
Best trial: 12. Best value: -0.21179:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [03:46<00:13,  3.27s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [03:51<00:13,  3.27s/it]
Best trial: 12. Best value: -0.21179:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [03:51<00:13,  3.27s/it]
Best trial: 12. Best value: -0.21179:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [03:51<00:11,  3.76s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [03:55<00:11,  3.76s/it]
Best trial: 12. Best value: -0.21179:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [03:55<00:11,  3.76s/it]
Best trial: 12. Best value: -0.21179:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [03:55<00:07,  3.96s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [04:05<00:07,  3.96s/it]
Best trial: 12. Best value: -0.21179:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [04:05<00:07,  3.96s/it]
Best trial: 12. Best value: -0.21179:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [04:05<00:05,  5.61s/it]
                                                                                     

Best trial: 12. Best value: -0.21179:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [04:09<00:05,  5.61s/it]
Best trial: 12. Best value: -0.21179:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [04:09<00:05,  5.61s/it]
Best trial: 12. Best value: -0.21179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [04:09<00:00,  5.30s/it]
Best trial: 12. Best value: -0.21179: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [04:09<00:00,  4.99s/it]
‚úÖ Best rmse: -0.2118
üìä Best parameters: {'n_estimators': 394, 'max_depth': 9, 'learning_rate': 0.06863000803064562, 'subsample': 0.7316936986365619, 'colsample_bytree': 0.8463063352248831, 'gamma': 0.03755154871269628, 'reg_alpha': 0.9374104377756843, 'reg_lambda': 1.305362400449962}
üíæ Model saved to: /home/user/app/outputs/models/tmp4thr4x2e.pkl
   ‚úì Completed: hyperparameter_tuning
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üîÑ Token budget reset (was 10676/500000)
üí∞ Token budget: 0/500000 (0%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10703 this call | 10703/500000 this minute

üîß Executing: perform_cross_validation
   Arguments: {
  "file_path": "./outputs/data/numeric_earthquake_data.csv",
  "target_col": "mag",
  "model_type": "xgboost",
  "task_type": "regression",
  "n_splits": 5,
  "cv_strategy": "kfold"
}
   üîÑ Converting Polars DataFrame to Pandas for XGBoost compatibility...
   ‚ö†Ô∏è Dropping 2 datetime columns: ['time', 'updated']
   üí° Time features should have been extracted in workflow step 7 (create_time_features)
   ‚ö†Ô∏è Dropping 8 string columns that weren't encoded: ['magType', 'net', 'id', 'place', 'type', 'status', 'locationSource', 'magSource']
   üí° Categorical encoding should have been done in workflow step 8
üîÑ Performing 5-fold cross-validation (kfold)...
  Fold 1: {'fold': 1, 'rmse': 0.21532516883364416, 'r2': 0.6846442591919986, 'samples': 35190}
  Fold 2: {'fold': 2, 'rmse': 0.21941414378114119, 'r2': 0.6819707343883556, 'samples': 35190}
  Fold 3: {'fold': 3, 'rmse': 0.21714031722900537, 'r2': 0.6835305732467218, 'samples': 35189}
  Fold 4: {'fold': 4, 'rmse': 0.21813022234327956, 'r2': 0.6860283685523745, 'samples': 35189}
  Fold 5: {'fold': 5, 'rmse': 0.21628395079804294, 'r2': 0.6808231423221587, 'samples': 35189}

‚úÖ Overall OOF rmse: 0.2173 (¬±0.0014)
   ‚úì Completed: perform_cross_validation
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üí∞ Token budget: 10703/500000 (2%)
üìä Tokens: 10635 this call | 21338/500000 this minute
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"

üîß Executing: generate_plotly_dashboard
   Arguments: {
  "file_path": "./outputs/data/numeric_earthquake_data.csv",
  "target_col": "mag",
  "output_dir": "./outputs/plots/"
}
   ‚úì Completed: generate_plotly_dashboard
‚úÇÔ∏è  Pruned conversation (keeping last 4 exchanges, ~4K tokens saved)
üîÑ Token budget reset (was 21338/500000)
üí∞ Token budget: 0/500000 (0%)
INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions "HTTP/1.1 200 OK"
üìä Tokens: 10769 this call | 10769/500000 this minute

‚úÖ Session saved: 9e7bbe07-2017-407d-88ed-50f24facbfac
INFO:src.api.app:Analysis completed: success
INFO:src.api.app:Cleaned up temporary file: /tmp/data_science_agent/usgs_earthquake_data_2000_2025.csv
INFO:     10.16.37.13:30772 - "POST /run HTTP/1.1" 200 OK
Exception ignored in: <function ResourceTracker.__del__ at 0x7f7e5c6b3100>
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/multiprocessing/resource_tracker.py", line 77, in __del__
  File "/usr/local/lib/python3.12/multiprocessing/resource_tracker.py", line 86, in _stop
  File "/usr/local/lib/python3.12/multiprocessing/resource_tracker.py", line 111, in _stop_locked
ChildProcessError: [Errno 10] No child processes
Exception ignored in: <function ResourceTracker.__del__ at 0x7f6d9c6b3100>
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/multiprocessing/resource_tracker.py", line 77, in __del__
  File "/usr/local/lib/python3.12/multiprocessing/resource_tracker.py", line 86, in _stop
  File "/usr/local/lib/python3.12/multiprocessing/resource_tracker.py", line 111, in _stop_locked
ChildProcessError: [Errno 10] No child processes